{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annan\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from countryinfo import CountryInfo\n",
    "import country_converter as coco\n",
    "from geopy.geocoders import Nominatim\n",
    "import json\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import pycountry\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import wbdata\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-957ea1cde474>:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  asylum = pd.read_csv('Data_for_reg_with0.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('qog_std_cs_jan23.csv')\n",
    "asylum = pd.read_csv('glob_data_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum = asylum[~asylum['citizen'].isin([1,'1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_ISO_3166_2_to_1 = {\n",
    "'AF':'AFG',\n",
    "'AX':'ALA',\n",
    "'AL':'ALB',\n",
    "'DZ':'DZA',\n",
    "'AS':'ASM',\n",
    "'AD':'AND',\n",
    "'AO':'AGO',\n",
    "'AI':'AIA',\n",
    "'AQ':'ATA',\n",
    "'AG':'ATG',\n",
    "'AR':'ARG',\n",
    "'AM':'ARM',\n",
    "'AW':'ABW',\n",
    "'AU':'AUS',\n",
    "'AT':'AUT',\n",
    "'AZ':'AZE',\n",
    "'BS':'BHS',\n",
    "'BH':'BHR',\n",
    "'BD':'BGD',\n",
    "'BB':'BRB',\n",
    "'BY':'BLR',\n",
    "'BE':'BEL',\n",
    "'BZ':'BLZ',\n",
    "'BJ':'BEN',\n",
    "'BM':'BMU',\n",
    "'BT':'BTN',\n",
    "'BO':'BOL',\n",
    "'BA':'BIH',\n",
    "'BW':'BWA',\n",
    "'BV':'BVT',\n",
    "'BR':'BRA',\n",
    "'IO':'IOT',\n",
    "'BN':'BRN',\n",
    "'BG':'BGR',\n",
    "'BF':'BFA',\n",
    "'BI':'BDI',\n",
    "'KH':'KHM',\n",
    "'CM':'CMR',\n",
    "'CA':'CAN',\n",
    "'CV':'CPV',\n",
    "'KY':'CYM',\n",
    "'CF':'CAF',\n",
    "'TD':'TCD',\n",
    "'CL':'CHL',\n",
    "'CN':'CHN',\n",
    "'CX':'CXR',\n",
    "'CC':'CCK',\n",
    "'CO':'COL',\n",
    "'KM':'COM',\n",
    "'CG':'COG',\n",
    "'CD':'COD',\n",
    "'CK':'COK',\n",
    "'CR':'CRI',\n",
    "'CI':'CIV',\n",
    "'HR':'HRV',\n",
    "'CU':'CUB',\n",
    "'CY':'CYP',\n",
    "'CZ':'CZE',\n",
    "'DK':'DNK',\n",
    "'DJ':'DJI',\n",
    "'DM':'DMA',\n",
    "'DO':'DOM',\n",
    "'EC':'ECU',\n",
    "'EG':'EGY',\n",
    "'SV':'SLV',\n",
    "'GQ':'GNQ',\n",
    "'ER':'ERI',\n",
    "'EE':'EST',\n",
    "'ET':'ETH',\n",
    "'FK':'FLK',\n",
    "'FO':'FRO',\n",
    "'FJ':'FJI',\n",
    "'FI':'FIN',\n",
    "'FR':'FRA',\n",
    "'GF':'GUF',\n",
    "'PF':'PYF',\n",
    "'TF':'ATF',\n",
    "'GA':'GAB',\n",
    "'GM':'GMB',\n",
    "'GE':'GEO',\n",
    "'DE':'DEU',\n",
    "'GH':'GHA',\n",
    "'GI':'GIB',\n",
    "'GR':'GRC',\n",
    "'GL':'GRL',\n",
    "'GD':'GRD',\n",
    "'GP':'GLP',\n",
    "'GU':'GUM',\n",
    "'GT':'GTM',\n",
    "'GG':'GGY',\n",
    "'GN':'GIN',\n",
    "'GW':'GNB',\n",
    "'GY':'GUY',\n",
    "'HT':'HTI',\n",
    "'HM':'HMD',\n",
    "'VA':'VAT',\n",
    "'HN':'HND',\n",
    "'HK':'HKG',\n",
    "'HU':'HUN',\n",
    "'IS':'ISL',\n",
    "'IN':'IND',\n",
    "'ID':'IDN',\n",
    "'IR':'IRN',\n",
    "'IQ':'IRQ',\n",
    "'IE':'IRL',\n",
    "'IM':'IMN',\n",
    "'IL':'ISR',\n",
    "'IT':'ITA',\n",
    "'JM':'JAM',\n",
    "'JP':'JPN',\n",
    "'JE':'JEY',\n",
    "'JO':'JOR',\n",
    "'KZ':'KAZ',\n",
    "'KE':'KEN',\n",
    "'KI':'KIR',\n",
    "'KP':'PRK',\n",
    "'KR':'KOR',\n",
    "'KW':'KWT',\n",
    "'KG':'KGZ',\n",
    "'LA':'LAO',\n",
    "'LV':'LVA',\n",
    "'LB':'LBN',\n",
    "'LS':'LSO',\n",
    "'LR':'LBR',\n",
    "'LY':'LBY',\n",
    "'LI':'LIE',\n",
    "'LT':'LTU',\n",
    "'LU':'LUX',\n",
    "'MO':'MAC',\n",
    "'MK':'MKD',\n",
    "'MG':'MDG',\n",
    "'MW':'MWI',\n",
    "'MY':'MYS',\n",
    "'MV':'MDV',\n",
    "'ML':'MLI',\n",
    "'MT':'MLT',\n",
    "'MH':'MHL',\n",
    "'MQ':'MTQ',\n",
    "'MR':'MRT',\n",
    "'MU':'MUS',\n",
    "'YT':'MYT',\n",
    "'MX':'MEX',\n",
    "'FM':'FSM',\n",
    "'MD':'MDA',\n",
    "'MC':'MCO',\n",
    "'MN':'MNG',\n",
    "'ME':'MNE',\n",
    "'MS':'MSR',\n",
    "'MA':'MAR',\n",
    "'MZ':'MOZ',\n",
    "'MM':'MMR',\n",
    "'NA':'NAM',\n",
    "'NR':'NRU',\n",
    "'NP':'NPL',\n",
    "'NL':'NLD',\n",
    "'AN':'ANT',\n",
    "'NC':'NCL',\n",
    "'NZ':'NZL',\n",
    "'NI':'NIC',\n",
    "'NE':'NER',\n",
    "'NG':'NGA',\n",
    "'NU':'NIU',\n",
    "'NF':'NFK',\n",
    "'MP':'MNP',\n",
    "'NO':'NOR',\n",
    "'OM':'OMN',\n",
    "'PK':'PAK',\n",
    "'PW':'PLW',\n",
    "'PS':'PSE',\n",
    "'PA':'PAN',\n",
    "'PG':'PNG',\n",
    "'PY':'PRY',\n",
    "'PE':'PER',\n",
    "'PH':'PHL',\n",
    "'PN':'PCN',\n",
    "'PL':'POL',\n",
    "'PT':'PRT',\n",
    "'PR':'PRI',\n",
    "'QA':'QAT',\n",
    "'RE':'REU',\n",
    "'RO':'ROU',\n",
    "'RU':'RUS',\n",
    "'RW':'RWA',\n",
    "'BL':'BLM',\n",
    "'SH':'SHN',\n",
    "'KN':'KNA',\n",
    "'LC':'LCA',\n",
    "'MF':'MAF',\n",
    "'PM':'SPM',\n",
    "'VC':'VCT',\n",
    "'WS':'WSM',\n",
    "'SM':'SMR',\n",
    "'ST':'STP',\n",
    "'SA':'SAU',\n",
    "'SN':'SEN',\n",
    "'RS':'SRB',\n",
    "'SC':'SYC',\n",
    "'SL':'SLE',\n",
    "'SG':'SGP',\n",
    "'SK':'SVK',\n",
    "'SI':'SVN',\n",
    "'SB':'SLB',\n",
    "'SO':'SOM',\n",
    "'ZA':'ZAF',\n",
    "'GS':'SGS',\n",
    "'ES':'ESP',\n",
    "'LK':'LKA',\n",
    "'SD':'SDN',\n",
    "'SR':'SUR',\n",
    "'SJ':'SJM',\n",
    "'SZ':'SWZ',\n",
    "'SE':'SWE',\n",
    "'CH':'CHE',\n",
    "'SY':'SYR',\n",
    "'TW':'TWN',\n",
    "'TJ':'TJK',\n",
    "'TZ':'TZA',\n",
    "'TH':'THA',\n",
    "'TL':'TLS',\n",
    "'TG':'TGO',\n",
    "'TK':'TKL',\n",
    "'TO':'TON',\n",
    "'TT':'TTO',\n",
    "'TN':'TUN',\n",
    "'TR':'TUR',\n",
    "'TM':'TKM',\n",
    "'TC':'TCA',\n",
    "'TV':'TUV',\n",
    "'UG':'UGA',\n",
    "'UA':'UKR',\n",
    "'AE':'ARE',\n",
    "'GB':'GBR',\n",
    "'US':'USA',\n",
    "'UM':'UMI',\n",
    "'UY':'URY',\n",
    "'UZ':'UZB',\n",
    "'VU':'VUT',\n",
    "'VE':'VEN',\n",
    "'VN':'VNM',\n",
    "'VG':'VGB',\n",
    "'VI':'VIR',\n",
    "'WF':'WLF',\n",
    "'EH':'ESH',\n",
    "'YE':'YEM',\n",
    "'ZM':'ZMB',\n",
    "'ZW':'ZWE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum =asylum.replace({\"citizen\":convert_ISO_3166_2_to_1}).replace({\"geo\":convert_ISO_3166_2_to_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asylum.to_csv('asylum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitale des pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pays = pd.read_csv('pays.csv',sep=\";\",encoding = 'ISO-8859-1')\n",
    "pays = pays[['Capital', 'ISO Code (3 letters)']]\n",
    "pays['Capital'] = pays['Capital'].replace('Yaound','Yaounde').replace(\"Copenagen\",\"Copenhagen\").replace(\"Reykjavk\",\"Reykjavik\")\n",
    "\n",
    "df = pd.merge(df,pays,how='left',left_on=['ccodealp'],right_on=['ISO Code (3 letters)'])\n",
    "df = df.drop(['ISO Code (3 letters)'], axis=1)\n",
    "\n",
    "\n",
    "# On obtient les coordonn√©es spatiales des capitales\n",
    "geolocator = Nominatim(user_agent=\"Your_Name\")\n",
    "df['capitale_lat'] = df.Capital.apply(lambda x: geolocator.geocode(x).latitude)\n",
    "df['capitale_long'] = df.Capital.apply(lambda x: geolocator.geocode(x).longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum = asylum.drop(['DATAFLOW','LAST UPDATE','freq','unit','asyl_app'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum = asylum.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "qog_dim = df[['ccodealp','capitale_lat','capitale_long']]\n",
    "asylum = pd.merge(asylum, qog_dim, how='left', left_on=['geo'], right_on=['ccodealp'])\n",
    "\n",
    "asylum = asylum.rename(columns={'capitale_lat':'capitale_lat_dest','capitale_long':'capitale_long_dest','ccodealp':'ccodealp_dest'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AND', 'ARE', 'AFG', 'ATG', 'ALB', 'ARM', 'AGO', 'ARG', 'AUT',\n",
       "       'AUS', 'AZE', 'BIH', 'BRB', 'BGD', 'BEL', 'BFA', 'BGR', 'BHR',\n",
       "       'BDI', 'BEN', 'BRN', 'BOL', 'BRA', 'BHS', 'BTN', 'BWA', 'BLR',\n",
       "       'BLZ', 'CAN', 'COD', 'CAF', 'COG', 'CHE', 'CIV', 'COK', 'CHL',\n",
       "       'CMR', 'CHN', 'COL', 'CRI', 'CUB', 'CPV', 'CYP', 'CZE', 'DEU',\n",
       "       'DJI', 'DNK', 'DMA', 'DOM', 'DZA', 'ECU', 'EST', 'EGY', 'ESH',\n",
       "       'GRC', 'ERI', 'ESP', 'ETH', 'FIN', 'FJI', 'FSM', 'FRA', 'GAB',\n",
       "       'GRD', 'GEO', 'GHA', 'GMB', 'GIN', 'GNQ', 'GTM', 'GNB', 'GUY',\n",
       "       'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IRL', 'ISR', 'IND', 'IRQ',\n",
       "       'IRN', 'ISL', 'ITA', 'JAM', 'JOR', 'JPN', 'KEN', 'KGZ', 'KHM',\n",
       "       'KIR', 'COM', 'KNA', 'PRK', 'KOR', 'KWT', 'KAZ', 'LAO', 'LBN',\n",
       "       'LCA', 'LIE', 'LKA', 'LBR', 'LSO', 'LTU', 'LUX', 'LVA', 'LBY',\n",
       "       'MAR', 'MCO', 'MDA', 'MNE', 'MDG', 'MHL', 'MKD', 'MLI', 'MMR',\n",
       "       'MNG', 'MRT', 'MLT', 'MUS', 'MDV', 'MWI', 'MEX', 'MYS', 'MOZ',\n",
       "       'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NRU', 'NZL', 'OMN',\n",
       "       'PAN', 'PER', 'PNG', 'PHL', 'PAK', 'POL', 'PSE', 'PRT', 'PLW',\n",
       "       'PRY', 'QAT', 'RNC', 'ROU', 'SRB', 'RUS', 'RWA', 'SAU', 'SLB',\n",
       "       'SYC', 'SDN', 'SWE', 'SGP', 'SVN', 'SVK', 'SLE', 'SMR', 'SEN',\n",
       "       'SOM', 'SUR', 'SS', 'STP', 'STLS', 'SLV', 'SYR', 'SWZ', 'TCD',\n",
       "       'TGO', 'THA', 'TJK', 'TLS', 'TKM', 'TUN', 'TON', 'TUR', 'TTO',\n",
       "       'TUV', 'TWN', 'TZA', 'UKR', 'UGA', 'GBR', 'UK_OCT', 'UNK', 'USA',\n",
       "       'URY', 'UZB', 'VAT', 'VCT', 'VEN', 'VNM', 'VUT', 'WSM', 'XK',\n",
       "       'YEM', 'ZAF', 'ZMB', 'ZWE'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asylum.citizen.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum = asylum = pd.merge(asylum, qog_dim, how='left', left_on=['citizen'], right_on=['ccodealp'])\n",
    "asylum = asylum.rename(columns={'capitale_lat':'capitale_lat_or','capitale_long':'capitale_long_or','ccodealp':'ccodealp_or'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance entre deux coordoon√©es\n",
    "def distance(lat1,lat2,lon1,lon2) :\n",
    "    R = 6373.0\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distance capitales\n",
    "asylum['dist_capit'] =  asylum.apply(lambda x: distance(x.capitale_lat_or,x.capitale_lat_dest,x.capitale_long_or,x.capitale_long_dest), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum = asylum.drop(['capitale_lat_dest','capitale_long_dest','capitale_lat_or','capitale_long_or'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion = pd.read_csv('religion.csv').drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(religion[religion['country_code']==\"Unknown code\"]['Country'])\n",
    "\n",
    "a[0] = 'Congo (the Democratic Republic of the)'\n",
    "a[1] = 'Congo (the)'\n",
    "a[2] = 'Sao Tome and Principe'\n",
    "a[3] = 'Tanzania, the United Republic of'\n",
    "a[4] = 'Cabo Verde'\n",
    "a[5] = 'Gambia (the)'\n",
    "a[6] = \"C√¥te d'Ivoire\"\n",
    "a[11] = \"Bolivia (Plurinational State of)\"\n",
    "a[13] = 'Venezuela (Bolivarian Republic of)'\n",
    "a[14] = 'China'\n",
    "a[16] = 'Taiwan (Province of China)'\n",
    "a[18] = 'Korea (the Republic of)'\n",
    "a[17] =  \"Korea (the Democratic People's Republic of)\"\n",
    "a[19] = 'Brunei Darussalam'\n",
    "a[20] = \"Lao People's Democratic Republic (the)\"\n",
    "a[21] = 'Viet Nam'\n",
    "a[22] = 'India'\n",
    "a[23] = 'Iran (Islamic Republic of)'\n",
    "a[25] = 'Syrian Arab Republic (the)'\n",
    "a[26] = 'Czechia'\n",
    "a[27] = 'Russian Federation (the)'\n",
    "a[29] = 'Moldova (the Republic of)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion1 = religion[religion['country_code']==\"Unknown code\"].reset_index()\n",
    "religion2 = religion[religion['country_code']!=\"Unknown code\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion1['Country'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion1 = religion1.drop(['index'],axis = 1)\n",
    "religion2 = religion2.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "qog = pd.read_csv('qog_std_cs_jan23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = qog.merge(religion2[['country_code','first_rel']],left_on='ccodealp',right_on='country_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = qog.merge(religion1[['Country','first_rel']],left_on=\"cname\",right_on=\"Country\",how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Country'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-e7f8434a5e21>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df3['first_rel'] = ['Christian','Christian','Christian','Christian','Christian']\n"
     ]
    }
   ],
   "source": [
    "a = list(df['cname'])\n",
    "b = list(qog['cname'])\n",
    "\n",
    "df3 = qog[qog['cname'].isin(list(set(a).symmetric_difference(b)))]\n",
    "df3['first_rel'] = ['Christian','Christian','Christian','Christian','Christian']\n",
    "\n",
    "qog = pd.concat([df,df3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum['religion_or'] = asylum[['ccodealp_or']].merge(qog[['ccodealp','first_rel']],left_on = 'ccodealp_or',right_on='ccodealp',how='left')['first_rel']\n",
    "asylum['religion_dest'] = asylum[['ccodealp_dest']].merge(qog[['ccodealp','first_rel']],left_on = 'ccodealp_dest',right_on='ccodealp',how='left')['first_rel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (asylum['religion_or'] == asylum['religion_dest']),\n",
    "    (asylum['religion_or'] != asylum['religion_dest'])]\n",
    "\n",
    "choices = ['Oui', 'Non']\n",
    "asylum['religion_commune'] = np.select(conditions, choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variable du QOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asylum_2018 = asylum[asylum['TIME_PERIOD']==2018][['citizen','geo','OBS_VALUE']]\n",
    "# qog_2018 = qog[qog['year']==2018].drop(['cname','ccode','year','cname_year','ccodealp_year','ccodecow','version'],axis=1)\n",
    "\n",
    "# qog_2018 = qog_2018[qog_2018.ccodealp.isin(list(asylum_2018.citizen))]\n",
    "\n",
    "# # On supprime les colonnes qui ont plus de 30 na\n",
    "# qog_2018 = qog_2018.dropna(thresh=len(qog_2018) - 30, axis=1)\n",
    "\n",
    "# # On supprime √† la main, les variables qui ne semblent pas adapt√©e\n",
    "# qog_2018 = qog_2018[qog_2018.columns.drop(list(qog_2018.filter(regex='wdi_')))]\n",
    "# qog_2018 = qog_2018[qog_2018.columns.drop(list(qog_2018.filter(regex='top_top')))]\n",
    "# qog_2018 = qog_2018[qog_2018.columns.drop(list(qog_2018.filter(regex='vdem_')))]\n",
    "# qog_2018 = qog_2018.drop(['pwt_pop','rd_inw','rd_outw','undp_hdi','van_index','atop_ally','bmr_demdur','mad_gdppc',\n",
    "#                          'p_durable','p_polity2','cspf_sfi'],axis=1)\n",
    "\n",
    "\n",
    "# # Imputation with KNN\n",
    "\n",
    "# KNNImputer(missing_values=np.nan, n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "# qog_2018_knn = qog_2018.drop(['ccode_qog','cname_qog','ccodealp'],axis=1)\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# qog_2018_knn = pd.DataFrame(scaler.fit_transform(qog_2018_knn), columns = qog_2018_knn.columns)\n",
    "\n",
    "# # Define KNN imputer and fill missing values\n",
    "# knn_imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "# qog_2018_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(qog_2018_knn), columns=qog_2018_knn.columns)\n",
    "\n",
    "# qog_2018_knn_imputed['cname_qog'] = list(qog_2018['cname_qog'])\n",
    "# qog_2018_knn_imputed['ccodealp'] = list(qog_2018['ccodealp'])\n",
    "\n",
    "# asylum_2018 = asylum_2018[asylum_2018['OBS_VALUE']!=0]\n",
    "\n",
    "\n",
    "# # Pearson for feature selection for origin country\n",
    "\n",
    "# df = asylum_2018[['citizen','OBS_VALUE']].groupby('citizen').sum().merge(qog_2018_knn_imputed, left_on='citizen', right_on='ccodealp').drop(['cname_qog'],axis=1)\n",
    "\n",
    "# def cor_selector(X, y,num_feats):\n",
    "#     cor_list = []\n",
    "#     feature_name = X.columns.tolist()\n",
    "#     # calculate the correlation with y for each feature\n",
    "#     for i in X.columns.tolist():\n",
    "#         cor = np.corrcoef(X[i], y)[0, 1]\n",
    "#         cor_list.append(cor)\n",
    "#     # replace NaN with 0\n",
    "#     cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "#     # feature name\n",
    "#     cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "#     # feature selection? 0 for not select, 1 for select\n",
    "#     cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "#     return cor_support, cor_feature\n",
    "\n",
    "# X = df.iloc[:,1:].drop('ccodealp',axis=1)\n",
    "# y = df.iloc[:,0]\n",
    "\n",
    "# cor_support, cor_feature = cor_selector(X, y,10)\n",
    "\n",
    "# print(str(len(cor_feature)), 'selected features',cor_feature)\n",
    "\n",
    "# origine_qog = cor_feature\n",
    "# origine_qog.append('ccodealp')\n",
    "\n",
    "# origine_qog = qog_2018_knn_imputed[origine_qog]\n",
    "\n",
    "# origine_qog = origine_qog.add_suffix('_origine')\n",
    "\n",
    "# # Pearson for feature selection for destination country\n",
    "\n",
    "# df = asylum_2018[['geo','OBS_VALUE']].groupby('geo').sum().merge(qog_2018_knn_imputed, left_on='geo', right_on='ccodealp').drop(['cname_qog'],axis=1)\n",
    "\n",
    "# def cor_selector(X, y,num_feats):\n",
    "#     cor_list = []\n",
    "#     feature_name = X.columns.tolist()\n",
    "#     # calculate the correlation with y for each feature\n",
    "#     for i in X.columns.tolist():\n",
    "#         cor = np.corrcoef(X[i], y)[0, 1]\n",
    "#         cor_list.append(cor)\n",
    "#     # replace NaN with 0\n",
    "#     cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
    "#     # feature name\n",
    "#     cor_feature = X.iloc[:,np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
    "#     # feature selection? 0 for not select, 1 for select\n",
    "#     cor_support = [True if i in cor_feature else False for i in feature_name]\n",
    "#     return cor_support, cor_feature\n",
    "\n",
    "# X = df.iloc[:,1:].drop('ccodealp',axis=1)\n",
    "# y = df.iloc[:,0]\n",
    "\n",
    "# cor_support, cor_feature = cor_selector(X, y,10)\n",
    "\n",
    "# print(str(len(cor_feature)), 'selected features',cor_feature)\n",
    "# cor_feature.remove('ht_region')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "qog = pd.read_csv('qog_bas_ts_jan23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "qog = qog[qog['year'].isin([2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables origine qui ont √©t√© s√©lectionn√©es plus haut\n",
    "origine = ['fh_status', 'fh_feb','wbgi_cce', 'fh_rol', 'fh_cl', 'fh_pair', 'wbgi_rle', 'wbgi_pve']\n",
    "#Variables dest qui ont √©t√© s√©lectionn√©es plus haut\n",
    "dest = [ 'fh_ep', 'fh_pr', 'ipu_l_sw', 'fh_fog', 'dr_ig',  'ht_region', 'wbgi_pve']\n",
    "or_dest = list(set(origine+dest))\n",
    "var = ['ccodealp','year'] + or_dest\n",
    "qog = qog[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "origine = list(asylum['citizen'].unique())\n",
    "dest = list(asylum['geo'].unique())\n",
    "pays = list(set(origine+dest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "qog = qog[qog['ccodealp'].isin(pays)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation with KNN\n",
    "\n",
    "KNNImputer(missing_values=np.nan, n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "\n",
    "qog_knn = qog.drop(['ccodealp','year'],axis=1)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "qog_knn = pd.DataFrame(scaler.fit_transform(qog_knn), columns = qog_knn.columns)\n",
    "\n",
    "# Define KNN imputer and fill missing values\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "qog_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(qog_knn), columns=qog_knn.columns)\n",
    "\n",
    "qog_knn_imputed['ccodealp'] = list(qog['ccodealp'])\n",
    "qog_knn_imputed['year'] = list(qog['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "qog_knn_imputed_origine = qog_knn_imputed[['ccodealp','year','fh_status', 'fh_feb','wbgi_cce', 'fh_rol', 'fh_cl', 'fh_pair', 'wbgi_rle', 'wbgi_pve']]\n",
    "qog_knn_imputed_dest = qog_knn_imputed[['ccodealp','year','fh_ep', 'fh_pr', 'ipu_l_sw', 'fh_fog', 'dr_ig',  'ht_region', 'wbgi_pve']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "qog_knn_imputed_origine = qog_knn_imputed_origine.add_suffix('_origine').rename(columns={'ccodealp_origine':'ccodealp','year_origine':'year'})\n",
    "qog_knn_imputed_dest = qog_knn_imputed_dest.add_suffix('_dest').rename(columns={'ccodealp_dest':'ccodealp','year_dest':'year'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finale = asylum.merge(qog_knn_imputed_origine,left_on=['citizen','TIME_PERIOD'],right_on=['ccodealp','year'],how='left').merge(qog_knn_imputed_dest,left_on=['citizen','TIME_PERIOD'],right_on=['ccodealp','year'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_finale.drop(['ccodealp_x','year_x','ccodealp_y','year_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ch√¥mage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "pays = list(list(df['citizen'].unique()) + list(df['geo'].unique()))\n",
    "pays.remove('TWN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp = pd.DataFrame(index=range(len(list(set(pays)))),columns=range(15))\n",
    "unemp.columns = ['country','2008','2009','2010','2011','2012','2013','2014','2015','2016','2017','2018','2019','2020','2021']\n",
    "unemp['country']= list(set(pays))\n",
    "#unemp = unemp[~unemp['country'].isin(['TWN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "indicator_code = \"SL.UEM.TOTL.ZS\"\n",
    "data_date = datetime.datetime(2008, 12, 31), datetime.datetime(2021, 12, 31) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(unemp)):\n",
    "    country_code = unemp['country'][i]\n",
    "    for j in range(1,15):\n",
    "        unemp.iloc[i,j] = wbdata.get_data(indicator=indicator_code, country=country_code, data_date=data_date)[j-1]['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemp.iloc[74,1] = unemp.iloc[4,2]\n",
    "unemp.iloc[157,1] = unemp.iloc[158,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "supp = list(unemp[unemp['2008'].isna()]['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['citizen'].isin(supp)]\n",
    "df = df[~df['geo'].isin(supp)]\n",
    "\n",
    "unemp = unemp[~unemp[\"2008\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008 = df[df['TIME_PERIOD']==2008]\n",
    "df_2009 = df[df['TIME_PERIOD']==2009]\n",
    "df_2010 = df[df['TIME_PERIOD']==2010]\n",
    "df_2011 = df[df['TIME_PERIOD']==2011]\n",
    "df_2012 = df[df['TIME_PERIOD']==2012]\n",
    "df_2013 = df[df['TIME_PERIOD']==2013]\n",
    "df_2014 = df[df['TIME_PERIOD']==2014]\n",
    "df_2015 = df[df['TIME_PERIOD']==2015]\n",
    "df_2016 = df[df['TIME_PERIOD']==2016]\n",
    "df_2017 = df[df['TIME_PERIOD']==2017]\n",
    "df_2018 = df[df['TIME_PERIOD']==2018]\n",
    "df_2019 = df[df['TIME_PERIOD']==2019]\n",
    "df_2020 = df[df['TIME_PERIOD']==2020]\n",
    "df_2021 = df[df['TIME_PERIOD']==2021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2008_bis = df_2008.merge(unemp[['country','2008']],left_on='citizen',right_on='country',how='left').rename(columns={'2008':'unemp_origine'}).merge(unemp[['country','2008']],left_on='geo',right_on='country',how='left').rename(columns={'2008':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2009_bis = df_2009.merge(unemp[['country','2009']],left_on='citizen',right_on='country',how='left').rename(columns={'2009':'unemp_origine'}).merge(unemp[['country','2009']],left_on='geo',right_on='country',how='left').rename(columns={'2009':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2010_bis = df_2010.merge(unemp[['country','2010']],left_on='citizen',right_on='country',how='left').rename(columns={'2010':'unemp_origine'}).merge(unemp[['country','2010']],left_on='geo',right_on='country',how='left').rename(columns={'2010':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2011_bis = df_2011.merge(unemp[['country','2011']],left_on='citizen',right_on='country',how='left').rename(columns={'2011':'unemp_origine'}).merge(unemp[['country','2011']],left_on='geo',right_on='country',how='left').rename(columns={'2011':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2012_bis = df_2012.merge(unemp[['country','2012']],left_on='citizen',right_on='country',how='left').rename(columns={'2012':'unemp_origine'}).merge(unemp[['country','2012']],left_on='geo',right_on='country',how='left').rename(columns={'2012':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2013_bis = df_2013.merge(unemp[['country','2013']],left_on='citizen',right_on='country',how='left').rename(columns={'2013':'unemp_origine'}).merge(unemp[['country','2013']],left_on='geo',right_on='country',how='left').rename(columns={'2013':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2014_bis = df_2014.merge(unemp[['country','2014']],left_on='citizen',right_on='country',how='left').rename(columns={'2014':'unemp_origine'}).merge(unemp[['country','2014']],left_on='geo',right_on='country',how='left').rename(columns={'2014':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2015_bis = df_2015.merge(unemp[['country','2015']],left_on='citizen',right_on='country',how='left').rename(columns={'2015':'unemp_origine'}).merge(unemp[['country','2015']],left_on='geo',right_on='country',how='left').rename(columns={'2015':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2016_bis = df_2016.merge(unemp[['country','2016']],left_on='citizen',right_on='country',how='left').rename(columns={'2016':'unemp_origine'}).merge(unemp[['country','2016']],left_on='geo',right_on='country',how='left').rename(columns={'2016':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2017_bis = df_2017.merge(unemp[['country','2017']],left_on='citizen',right_on='country',how='left').rename(columns={'2017':'unemp_origine'}).merge(unemp[['country','2017']],left_on='geo',right_on='country',how='left').rename(columns={'2017':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2018_bis = df_2018.merge(unemp[['country','2018']],left_on='citizen',right_on='country',how='left').rename(columns={'2018':'unemp_origine'}).merge(unemp[['country','2018']],left_on='geo',right_on='country',how='left').rename(columns={'2018':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2019_bis = df_2019.merge(unemp[['country','2019']],left_on='citizen',right_on='country',how='left').rename(columns={'2019':'unemp_origine'}).merge(unemp[['country','2019']],left_on='geo',right_on='country',how='left').rename(columns={'2019':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2020_bis = df_2020.merge(unemp[['country','2020']],left_on='citizen',right_on='country',how='left').rename(columns={'2020':'unemp_origine'}).merge(unemp[['country','2020']],left_on='geo',right_on='country',how='left').rename(columns={'2020':'unemp_dest'}).drop(['country_x','country_y'],axis=1)\n",
    "df_2021_bis = df_2021.merge(unemp[['country','2021']],left_on='citizen',right_on='country',how='left').rename(columns={'2021':'unemp_origine'}).merge(unemp[['country','2021']],left_on='geo',right_on='country',how='left').rename(columns={'2021':'unemp_dest'}).drop(['country_x','country_y'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum = pd.concat([df_2008_bis,df_2009_bis,df_2010_bis,df_2011_bis,df_2012_bis,df_2013_bis,df_2014_bis,df_2015_bis,df_2016_bis,df_2017_bis,df_2018_bis,df_2019_bis,df_2020_bis,df_2021_bis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.to_csv('asylum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
